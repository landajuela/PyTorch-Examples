{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Experiments with `torch.autograd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Python version is 3.8.9\n",
      "The Torch version is: 1.10.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torch.autograd import grad\n",
    "from wolframclient.evaluation import WolframLanguageSession\n",
    "from wolframclient.language import wl\n",
    "session = WolframLanguageSession()\n",
    "print(\"The Python version is %s.%s.%s\" % sys.version_info[:3])\n",
    "print(f'The Torch version is: {torch.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $f(w, z) = w+2z \\longrightarrow \\nabla f=(1,2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.evaluate('f[w_, z_] := w + 2 z; Grad[f[w, z], {w, z}]') # Compute the gradient symbolically in Mathematica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dw,dz] = [1.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "w = torch.ones(1, requires_grad=True)   #  w.requires_grad = True\n",
    "z = torch.ones(1, requires_grad=True)   #  z.requires_grad = False\n",
    "f = w + 2*z     #  total.requires_grad = True\n",
    "# Automatic differentiation is straightforward:\n",
    "[dw,dz] = grad(f,[w,z])\n",
    "print(\"[dw,dz] = [{}, {}]\".format(dw.item(),dz.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use of `backward()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dw,dz] = [1.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "w = torch.ones(1, requires_grad=True)   #  w.requires_grad = True\n",
    "z = torch.ones(1, requires_grad=True)   #  z.requires_grad = False\n",
    "f = w + 2*z     #  total.requires_grad = True\n",
    "f.backward()\n",
    "print(\"[dw,dz] = [{}, {}]\".format(w.grad.item(),z.grad.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $f(w,z) =w+\\sin(2z)\\longrightarrow \\nabla f(1,2)=(1.,-1.3072872417272239)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, -1.3072872417272239)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.evaluate('f[w_, z_] := w + Sin[2 z]; N@Grad[f[w, z], {w, z}]/. {w -> 1, z -> 2}') # Compute the gradient symbolically in Mathematica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dw,dz] = [1.0, -1.3072872161865234]\n"
     ]
    }
   ],
   "source": [
    "w = torch.ones(1, requires_grad=True)   #  w.requires_grad = True\n",
    "z = torch.ones(1, requires_grad=True)*2   #  z.requires_grad = False\n",
    "f = w + torch.sin(2*z)     #  total.requires_grad = True\n",
    "# Automatic differentiation is straightforward:\n",
    "[dw,dz] = grad(f,[w,z])\n",
    "print(\"[dw,dz] = [{}, {}]\".format(dw.item(),dz.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $g_1(w,z)=3w+\\cos(z), \\\\ g_2(w,z)=w^2+\\sin(2z),\\\\ f(w,z) = \\exp(g_1(w,z))+3 g_2(w,z)$ $\\longrightarrow \\nabla f(1,1)=(109.43202095367012,-31.508562530134782)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[dw,dz] ={109.432, -31.5086}'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.evaluate(\"g1[w_, z_] := 3 w + Cos[z]; \\\n",
    "g2[w_, z_] := w^2 + Sin[2 z]; \\\n",
    "f[w_, z_] := Exp[g1[w, z]] + 3 g2[w, z]; \\\n",
    "\\\"[dw,dz] =\\\" <> ToString[N[Grad[f[w, z], {w, z}]] /. {w -> 1, z -> 1}]\") # Compute the gradient symbolically using the Wolfram language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dw,dz] = [109.43202209472656, -31.508562088012695]\n"
     ]
    }
   ],
   "source": [
    "w = torch.ones(1, requires_grad=True)\n",
    "z = torch.ones(1, requires_grad=True)\n",
    "g1 = 3*w + torch.cos(z)\n",
    "g2 = torch.pow(w,2) + torch.sin(2*z)\n",
    "f = torch.exp(g1) + 3*g2\n",
    "[dw,dz] = grad(f,[w,z])\n",
    "print(\"[dw,dz] = [{}, {}]\".format(dw.item(),dz.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $G_1(W,Z)=3W+\\cos(Z), \\\\ G_2(W,Z)=W^2+\\sin(2Z),\\\\ F(W,Z) = \\exp(G_1(W,Z))+G_1(W,Z)G_2(W,Z)  \\longrightarrow \\ \\nabla_W F (W_0, Z_0) ,\\nabla_Z F (W_0,Z_0) ?$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row[{'F': 56.8399608952662, 'dW': (136.20676537164832, 17.023950389816783, 8.303863404839616, 2.58710109650704), 'dZ': (-26.11500277154785, 2.0506692211505397, 3.4805666706618235, -0.7192011140151858)}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.evaluate(\"g1[W_, Z_] := 3 W + Cos[Z];\\\n",
    "g2[W_, Z_] := W . W + Sin[2 Z];\\\n",
    "f[W_, Z_] := Norm[Exp[g1[W, Z]] + g1[W, Z] . g2[W, Z], \\\"Frobenius\\\"];\\\n",
    "Ws = {{w11, w12}, {w21, w22}};\\\n",
    "Zs = {{z11, z12}, {z21, z22}};\\\n",
    "W = {{1, 0.5}, {0.2, 0.1}} ;\\\n",
    "Z = {{0.7, 0.1}, {0.34, 0.9}} ;\\\n",
    "Row[AssociationThread[{\\\"F\\\", \\\"dW\\\", \\\"dZ\\\"} ->{N[f[Ws, Zs] /. Thread[Flatten[Ws] -> Flatten[W]]~Join~Thread[Flatten[Zs] -> Flatten[Z]]~Join~{Derivative[1][Abs][p_] -> 1}],\\\n",
    "N[Grad[f[Ws, Zs], Flatten[Ws]]] /. Thread[Flatten[Ws] -> Flatten[W]]~Join~Thread[Flatten[Zs] -> Flatten[Z]]~Join~{Derivative[1][Abs][p_] -> 1},\\\n",
    "N[Grad[f[Ws, Zs], Flatten[Zs]]] /. Thread[Flatten[Ws] -> Flatten[W]]~Join~Thread[Flatten[Zs] -> Flatten[Z]]~Join~{Derivative[1][Abs][p_] -> 1}}]]\") # Compute the gradient symbolically in Mathematica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F = 56.839962005615234\n",
      "dW = tensor([[136.2068,  17.0240],\n",
      "        [  8.3039,   2.5871]])\n",
      "dZ = tensor([[-26.1150,   2.0507],\n",
      "        [  3.4806,  -0.7192]])\n"
     ]
    }
   ],
   "source": [
    "W = torch.tensor([[1,0.5],[0.2,0.1]], requires_grad=True)\n",
    "Z = torch.tensor([[0.7,0.1],[0.34,0.9]], requires_grad=True)\n",
    "G1 = 3*W + torch.cos(Z)\n",
    "G2 = torch.matmul(W, W) + torch.sin(2*Z)\n",
    "F = torch.norm(torch.exp(G1) + torch.matmul(G1, G2),p = 2) #  total.requires_grad = True\n",
    "print(\"F = {}\".format(F))\n",
    "F.backward()\n",
    "print(\"dW = {}\".format(W.grad))\n",
    "print(\"dZ = {}\".format(Z.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
