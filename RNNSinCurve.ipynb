{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning $\\sin(t)$ with a Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we train a Recurrent Neural Network to predict the sequence given by $sin(t)$. More precisely, we want to reproduce the following sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.1\n",
    "dataSin = np.sin(np.arange(0.0, 100.0, h))\n",
    "plt.plot(dataSin, 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will cut the data in windows of <br>\n",
    "$$partition = memory + offset$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data points. The first memory points is the input variable, and the last future data points is the target variable: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\{y_{i-memory},y_{i-(memory-1)},\\cdots, y_{i-1}\\}  \\rightarrow \\{ y_{(i + offset) - future}, y_{(i + offset) - (future-1)}, \\cdots, y_{(i + offset) - 1} \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the Dataset object to manage the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinDataset(Dataset):\n",
    "    \"\"\" Sin(x) dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, h_size, memory, future, offset):\n",
    "        \n",
    "        # Generate the sin sequence \n",
    "        data = torch.sin(torch.arange(0.0, 100.0, h_size))\n",
    "        \n",
    "        partition = memory + offset\n",
    "        \n",
    "        XY = torch.zeros(len(data) - partition, partition)\n",
    "        \n",
    "        self.len = XY.shape[0]\n",
    "        \n",
    "        for i in range(self.len):\n",
    "            XY[i, :] = data[i:i + partition]\n",
    "        \n",
    "        self.x_data = XY[:,0:memory]\n",
    "        self.y_data = XY[:,-future:]\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We creeate a RNN with a readout layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first = True, nonlinearity = 'tanh')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        # h0.shape must be torch.Size([layer_dim, batch_size, hidden_dim])\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim)\n",
    "            \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define an initialization function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialitation\n",
    "def init_weights(self):\n",
    "    for m in self.modules():\n",
    "        if type(m) in [nn.GRU, nn.LSTM, nn.RNN]:\n",
    "            for name, param in m.named_parameters():\n",
    "                print(f'Initialization of {name}', end=\"\", flush=True)\n",
    "                if 'weight_ih' in name:   \n",
    "                    torch.nn.init.xavier_uniform_(param.data)\n",
    "                    print('...done')\n",
    "                elif 'weight_hh' in name:\n",
    "                    torch.nn.init.orthogonal_(param.data)\n",
    "                    print('...done')\n",
    "                elif 'bias' in name:\n",
    "                    param.data.fill_(0)\n",
    "                    print('...done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the training process: Model + Loss + Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data parameters\n",
    "h_size = 0.1\n",
    "memory = 10\n",
    "future = 10\n",
    "offset = 1\n",
    "\n",
    "# Global parameters\n",
    "input_dim = 1      # input dimension\n",
    "hidden_dim = 100   # hidden layer dimension\n",
    "layer_dim = 1      # number of hidden layers\n",
    "output_dim = 1     # output dimension\n",
    "\n",
    "# Dataset\n",
    "dataset = SinDataset(h_size, memory, future, offset)\n",
    "# DataLoader\n",
    "train_loader = DataLoader(dataset = dataset,\n",
    "                          batch_size = 32,\n",
    "                          shuffle = True)\n",
    "                          #num_workers = 1)\n",
    "\n",
    "# Model\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "# Initialization                  \n",
    "model.apply(init_weights)\n",
    "\n",
    "# Criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    " \n",
    "        # Get the inputs\n",
    "        XX, yy = data\n",
    "\n",
    "        # X.shape = torch.Size([32, 7])\n",
    "        # y.shape = torch.Size([32, 7])\n",
    "        # We need to reshape these vectors to be torch.Size([32, 7, 1]) \n",
    "        X = XX.view(-1, memory, input_dim)\n",
    "        y = yy.view(-1, memory, input_dim)\n",
    "\n",
    "        # Train step\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_ = model(X)\n",
    "        loss = criterion(y_, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            if i % 16 == 0:        \n",
    "                # Evaluation\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    y_ = model(X)\n",
    "\n",
    "                # Compute and print loss\n",
    "                loss = criterion(y_, y)\n",
    "                \n",
    "                print(f'Epoch : {epoch}, Iteration : {i}, Loss : {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Investigate the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # Starting sequence\n",
    "    h = 0.1\n",
    "    dataSin = torch.sin(torch.arange(0.0, 50.0, h))\n",
    "    \n",
    "    # Initial sequence\n",
    "    seq = dataSin[0:memory]\n",
    "   \n",
    "    # Predicted list of values\n",
    "    dataSin_pred = seq[:].numpy().tolist()\n",
    "    \n",
    "    \n",
    "    # Model in evaluation state\n",
    "    model.eval()      \n",
    "    \n",
    "    for i in range(500):\n",
    "        \n",
    "        seq = seq.view(-1, memory, input_dim)\n",
    "        \n",
    "        # Evalaute the model\n",
    "        y_ = model(seq)\n",
    "          \n",
    "        # Create the next sequence of seq_dim lenght to be avaluated by the model\n",
    "        seq = torch.cat((seq[:,offset:,:], y_[:,-offset:,:].view(-1, offset, 1)), 1)    \n",
    "\n",
    "    \n",
    "        # Append to the predicted list\n",
    "        dataSin_pred = dataSin_pred + y_[0,-offset:,0].numpy().tolist()\n",
    "        \n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(dataSin.numpy(),\".\", label=\"data\")\n",
    "    ax.plot(dataSin_pred, \".\", label=\"pred\")\n",
    "    ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
